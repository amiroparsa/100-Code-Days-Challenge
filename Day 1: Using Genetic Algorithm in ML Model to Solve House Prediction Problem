import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Generate a synthetic dataset
X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, random_state=42)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the fitness function to evaluate the fitness of each candidate solution
def fitness_function(features):
    X_train_subset = X_train[:, features]
    X_test_subset = X_test[:, features]
    clf = LogisticRegression(random_state=42)
    clf.fit(X_train_subset, y_train)
    y_pred = clf.predict(X_test_subset)
    return accuracy_score(y_test, y_pred)

# Define the genetic algorithm function
def genetic_algorithm(population_size, fitness_function, n_generations, mutation_rate=0.1):
    n_features = X.shape[1]
    population = np.random.choice([0, 1], size=(population_size, n_features))
    for i in range(n_generations):
        fitness_scores = [fitness_function(features) for features in population]
        elite_index = np.argmax(fitness_scores)
        elite_features = population[elite_index]
        new_population = [elite_features]
        while len(new_population) < population_size:
            parent1, parent2 = np.random.choice(population, size=2)
            child = parent1.copy()
            for j in range(n_features):
                if np.random.uniform() < mutation_rate:
                    child[j] = 1 - child[j]
            new_population.append(child)
        population = np.array(new_population)
    best_features = population[elite_index]
    return best_features

# Run the genetic algorithm with a population size of 50 and 100 generations
best_features = genetic_algorithm(population_size=50, fitness_function=fitness_function, n_generations=100)

# Train a logistic regression model on the selected features
X_train_subset = X_train[:, best_features.astype(bool)]
X_test_subset = X_test[:, best_features.astype(bool)]
clf = LogisticRegression(random_state=42)
clf.fit(X_train_subset, y_train)
y_pred = clf.predict(X_test_subset)
accuracy = accuracy_score(y_test, y_pred)

print("Selected features:", np.where(best_features)[0])
print("Accuracy:", accuracy)

